# Kubernetes

Kubernetes √© um orquestrador de containers capaz de resolver todos os problemas de v√°rios containers rodando ao mesmo tempo.

- Kubernetes √© capaz de criar e gerenciar um cluster para que n√≥s consigamos manter a nossa aplica√ß√£o est√°vel
sempre que n√≥s quisermos adicionar novos containers, sempre que n√≥s quisermos reiniciar a nossa aplica√ß√£o de maneira 
autom√°tica, caso ela tenha falhado. Ent√£o n√≥s chamamnos isso de __orquestra√ß√£o de containers__

- Quando duas m√°quinas antinjam o seu limite de poder computacional em algum momento, o kubernetes tamb√©m √© capaz de criar uma nova m√°quina dentro de nosso cluster para que n√≥s consigamos tamb√©m adicionar mais container √† essas m√°quinas e isso √© claro, uma m√°quina virtual. N√≥s n√£o vamos manipular uma m√°quina f√≠sica aqui na nossa casa ou no nosso ambiente
de trabalho.

# A arquitetura do kubernetes

> Recursos
> - POD
> - RS
> - DEPLOY
> - VOL
> - HPA
> - PV
> - IMG
> - PVC
> - SVC
> - SC
> - DS 
> - QUOTA

PODS s√£o mais do um recurso que encapsula um container no kubernete.N√≥s nunca vamos utilizar um container propriamente, n√≥s vamos utilizar pods.

- Elas podem ser master, onde o master √© respons√°vel por coordenar e gerenciar todo o nosso luster e n√≥s temos os nodes que s√£o respons√°veis pela execu√ß√£o do trabalho duro, para executar os nossos pods em capsulas containers, por assim dizer.


__master:__
- Gerenciar o cluster
- Manter e atualiza o estado
- Receber e executar novos comandos
    - control plane
        - API
        - C-M
        - SCHED
        - etcd

__node:__
- Executar as aplica√ß√µes
  - ***Node***
    - kubelet
    - k-proxy

![](https://s.profissionaisti.com.br/wp-content/uploads/2018/07/kubernetes-arquitetura.jpg)

O comando kubectl ele:
- cria --> run
- ler --> get
- atualizar --> edit
- remove --> delete

De forma __declarativa ou imperativo__
![](https://cdn-icons-png.flaticon.com/128/8790/8790376.png)

### Entendendo a API

__Como a comunica√ß√£o √© feita com a API?__

- Utilizando uma ferramenta chamada kubectl

## Cluster no linux

> **Baixar o miniekube e kubectl**
> **Baixar o virtualbox**

**Comando para inicializar o cluster no virtualbox**

```shell 
minekube start --vm-driver=virtualbox
```

**Verificar a quantiade de n√≥s e algumas informa√ß√µes de n√≥**

```shell
kubectl get nodes
```

## Entendendo o que s√£o pods.
> **Pode conter 1 ou mais containers de maneira declarativa ou imperativa.**

Quando criamos um pod ele ganha um endere√ßo ip e dentro do Pod n√≥s temos total liberdade de fazer um mapeamento de portas

***OBS!!*** N√£o pode existir 2 containers dentro de pod com as mesma porta

- Em caso de um √∫nico container falhar nesse momento, o pod vai parar de funcionar, kubernets vai criar um novo pod, mas com o endere√ßo ip diferente do antigo pod.
  
    - **Pods s√£o ef√™meros!**
    - **S√£o substituidos a qualquer momento**

üîµ Caso exista 2 containers dentro de um pod, e um  dos containers pare de funcionar, o outro vai estar rodando normal, logo, esse pod ainda vai estar funcionando normalmente.

üîµ Se caso os 2 containers parem de funcionar, ai sim o pod √© finalizado! Outro ser√° criado em seu lugar!


- Compartilham namespaces de rede e ipc
- podem compartilhar volumes
  

**IPC -> Comunica√ß√£o entre processos, √© o grupo de macanismo que permite aos processos transferirem informa√ß√µes entre si.**

Dentro do pod, containers podem se comunicar via localhost com o mesmo ip do pod.

- Como possuem IPs diferentes, containers em pods diferentes podem utilizar o mesmo n√∫mero de porta.
- containers dentro de mesmo pod conseguem de comunicar via localhost.

## Criando o primeiro POD de forma Imperativa

**Cria POD**
    
    kubectl run nginx-pod --image=nginx:latest

**Mostrar nossos PODs**

    kubectl get pods

**Mostrar nossos pods sendo executados em tempo real**

    kubectl get pods --watch

**Para descrever um POD**

    kubectl describe pod <nomePod>

**Para editar um POD**

    kubectl edit pod <pod>

## Para Saber mais: Onde as imagens s√£p armazenadas.

Executamos o nosso primeiro Pod. Por√©m, como o Kubernetes armazena as imagens baixadas dentro do cluster?

A resposta √© simples: quando definimos que um Pod ser√° executado, o scheduler definir√° em qual Node isso acontecer√°. O resultado ent√£o √© que as imagens quando baixadas de reposit√≥rios como o Docker Hub, ser√£o armazenadas localmente em cada Node, n√£o sendo compartilhada por padr√£o entre todos os membros do cluster.

## Criando Pods de maneira declarativa

- Crie um arquivo yaml

```yaml

#versao da api
apiVersion: v1
#informar o tipo de recurso
kind: Pod
#Definir informa√ß√µes
metadata:
  name: primeiro-pod-declarativo
#Especifica√ß√µes
spec:
  containers:
      #posso colocar qualquer nome
    - name: nginx-container
      #imagem
      image: nginx:latest
    #  - name: nginx-container
    #   #imagem
    #   image: nginx:latest
    #  - name: nginx-container
    #   #imagem
    #   image: nginx:latest

# OBS! - separa containers, posso colocar varios containers

```
'-' = Separa cada container; posso criar v√°rios containers dentro de um pod

**Para aplicar/criar o pod, digite o seguinte comando**

> kubctl apply -f <arquivo.yaml>

**Deletando pods**

    kubectl delete pod nginx-pod

ou

    kubectl delete -f <arquivo>

**Para executar pod de maneira iterativa**

     kubectl exec -it <namePod> -- bash

### Quando um pod √© dado como encerrado?

> **Quando todos os containers dentro do pod param de funcionar.**

## Explorando pods com services

### Conhecendo services

**Comando que mostra mais informa√ß√£o sobre o pod incluindo o ip**

    kubectl get pods -o wide

**Service(SVC)**

> - **Abstra√ß√£o para expor aplica√ß√µes executando em um ou mais pods**
> - **Proveem IP's fixos para comunica√ß√£o**
> - **Proveem um DNS para um ou mais pods**
> - **S√£o capazes de fazer balanceamento de carga**

 - ClusterIp
 - NodePort
 - LoadBlance

### Vantagens de service

 - Fazem balanceamento de carga
 - Proveem IP's fixos para comunica√ß√£o

**Comando para mostrar servi√ßos**

    kubectl get svc

### Arquivo yaml de um SVC

```yaml
apiVersion: v1
kind: Service
metadata:
  name: svc-pod-2
spec:
  type: ClusterIP
  selector:
    app: segundo-pod
  ports:
    - port: 80

```

**OBS! Ao criar uma label, ele v√£o receber uma chave e um valor**

> Podemos utilizar/criar v√°rias labels


10.1.0.67:50 -> Ela n√£o √© est√°vel

**Redireciona o ip do svc para o ip do pod**

- A porta pode variar

10.111.155.166:9000 --> 172.17.0.4:80

**Como um service sabe quais pods deve gerenciar?**

> Atrav√©s de **labels** definidas no **metadata** e utilizando o campo **selector** no service.

**O que √© um ClusterIP?**

Um servi√ßo ClusterIP √© o servi√ßo padr√£o do Kubernetes. Ele fornece um servi√ßo dentro do cluster que outros aplicativos dentro do cluster podem acessar. N√£o h√° acesso externo.

![](https://miro.medium.com/max/1400/1*I4j4xaaxsuchdvO66V3lAg.webp)

### Criando um Node Port

```yaml
apiVersion: v1
kind: Service
metadata:
  name: svc-pod-1
spec:
  type: NodePort
  ports:
    - port: 80
  selector:
    app: primeiro-pod
```

**O que √© um NodePort?**

Um servi√ßo NodePort √© a maneira mais primitiva de obter tr√°fego externo diretamente para seu servi√ßo. NodePort, como o nome indica, abre uma porta espec√≠fica em todos os n√≥s (as VMs), e qualquer tr√°fego enviado para essa porta √© encaminhado para o servi√ßo.

![](https://miro.medium.com/max/1400/1*CdyUtG-8CfGu2oFC5s0KwA.webp)

Basicamente, um servi√ßo NodePort tem duas diferen√ßas de um servi√ßo ‚ÄúClusterIP‚Äù normal. Primeiro, o tipo √© ‚ÄúNodePort‚Äù. H√° tamb√©m uma porta adicional chamada nodePort que especifica qual porta abrir nos n√≥s. Se voc√™ n√£o especificar esta porta, ela escolher√° uma porta aleat√≥ria. Na maioria das vezes, voc√™ deve deixar o Kubernetes escolher a porta; Como chocante diz, h√° muitas ressalvas sobre quais portas est√£o dispon√≠veis para voc√™ usar.

**Quando usar?**

Existem muitas desvantagens nesse m√©todo:

1. Voc√™ s√≥ pode ter um servi√ßo por porta
2. Voc√™ s√≥ pode usar as portas 30000‚Äì32767
3. Se o endere√ßo IP do seu Node/VM ‚Äã‚Äãmudar, voc√™ precisa lidar com isso.

Por esses motivos, n√£o recomendo usar esse m√©todo em produ√ß√£o para expor diretamente seu servi√ßo. Se voc√™ estiver executando um servi√ßo que n√£o precisa estar sempre dispon√≠vel ou for muito sens√≠vel aos custos, esse m√©todo funcionar√° para voc√™. Um bom exemplo de tal aplicativo √© um aplicativo de demonstra√ß√£o ou algo tempor√°rio.

**Mostrar o IP dos n√≥**

    kubectl get nodes -o wide

**obs! Para ter acesso a aplica√ß√£o no kluster no linux √© preciso acessar o internal-ip:nodePort, j√° no windows √© so localhost:nodePort.**

```shell
NAME          TYPE        CLUSTER-IP      PORT(S)               
svc-1       NodePort     10.101.214.22   80:30000/TCP
```
- Dentro do cluster o service escuta na porta 80, enquanto fora do cluster escuta na porta 30000.
- Utilizamos o IP do n√≥ para acessar o service atrav√©s da porta 30000.

###  Criando um Load Balancer

LoadBalancer nada mais √© do que um ClusterIP que permite a comunica√ß√£o entre uma mna do mundo externo e os nosso pods. S√≥ que ele automaticamente se integra ao LoadBalancer do nosso cloud provider.

- Utilizam automaticamente os balanceadores de carga de cloud providers.
- Por serem um Load Balancer, tamb√©m s√£o um NodePort e ClusterIP ao mesmo tempo.
- Um servi√ßo LoadBalancer √© a maneira padr√£o de expor um servi√ßo √† Internet. No GKE, isso ativar√° um balanceador de carga de rede que fornecer√° um √∫nico endere√ßo IP que encaminhar√° todo o tr√°fego para seu servi√ßo.

![](https://miro.medium.com/max/1400/1*P-10bQg_1VheU9DRlvHBTQ.webp)

**Quando usar?**

Se voc√™ deseja expor diretamente um servi√ßo, este √© o m√©todo padr√£o. Todo o tr√°fego na porta que voc√™ especificar ser√° encaminhado para o servi√ßo. N√£o h√° filtragem, roteamento, etc. Isso significa que voc√™ pode enviar quase qualquer tipo de tr√°fego para ele, como HTTP, TCP, UDP, Websockets, gRPC ou qualquer outro.

## Resumo do m√≥dulo:

- O que s√£o e para que servem os Services
- Como garantir estabilidade de IP e DNS
- Como criar um Service
- Labels s√£o respons√°veis por definir a rela√ß√£o Service x Pod
- Um ClusterIP funciona apenas dentro do cluster
- Um NodePort exp√µe Pods para dentro e fora do cluster
- Um LoadBalancer tamb√©m √© um NodePort e ClusterIP
- Um LoadBalancer √© capaz de automaticamente utilizar um balanceador de carga de um cloud provider

## Aplicando services ao projeto

### Acessando o Portal

